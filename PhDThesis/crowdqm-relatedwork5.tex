Community Question Answering forums are increasingly used to seek advice online; however, they often contain conflicting and unreliable information. This misinformation could lead to serious consequences to the users. Thus, most of the work that model user behavior in CQA forums deals with predicting user reliability or quality of posted answers to a question.

Prior works can be classified into Feature-driven models; which use user and content-based engineered features for the task; another is Deep Text models that only model relevance of the content of question and answers for prediction and disregard user information. Recently, unsupervised approaches based on Truth Discovery principle are applied to model user expertise and answer quality simultaneously in these forums.

\noindent
\emph{Feature-Driven Model:}
Feature-driven models \cite{BurelMA16} develop features from three different perspectives: user features, content features, and thread features.
These features are fed into classifiers, such as tree-based models \cite{BurelMA16, JendersKN16, TianZL13} to identify the best answer. \citet{TianZL13} found that the best answer is usually the earlier and most different one, and tends to have more details and comments. \citet{JendersKN16} trained several classifiers for online MOOC forums. Different from existing works, \citet{BurelMA16} emphasize on the thread-like structure of question \& answer and introduce four thread-based normalization methods. These models predict the answer label independently of the other answers for the question.
CQARank leverages voting information as well as user history and estimates user interests and expertise on different topics ~\cite{yang2013cqarank}. \citet{barron2015thread} also look at the relationship between the answers, measuring textual and structural similarities between them to classify useful and relevant answers. All these supervised approaches need a large amount of labeled training data ~\cite{wen2018hybrid, mihaylova2018fact,oh2013finding}. However, it is expensive and unsustainable to curate each answer manually for training these models. Alternatively, forums employ crowd sourced voting mechanisms to estimate information reliability but it could lead to under-provision \cite{gilbert2013widespread}.

\noindent
\emph{Deep Text Models:} Text-based deep learning models learn an optimal representation of question-answer text pairs suitable to select the best answer \cite{ZhangLSW17, WuWS18, WangN15}. In SemEval 2017 on Community Question Answering (CQA),~\cite{nakov2017semeval} developed a task to recommend useful related answers to a new question in the forum.
SemEval 2019 further extends this line of work by proposing fact checking in community question answering~\cite{Mihaylova2019semeval}. \citet{FengXGWZ15} augment CNN with discontinuous convolution for a better vector representation; \citet{WangN15} uses a stacked biLSTM to match question and answer semantics. \citet{SukhbaatarSWF15} use attention mechanism in an end-to-end memory framework. Text-based models take longer to train and are computationally expensive.

\noindent
\emph{Truth discovery:} Different approaches based on truth discovery principle have been proposed to address predict answer quality in CQA forums~\cite{zhang2018texttruth, li2015discovery, zheng2017truth,li2016crowdsourcing,mukherjee2016truthcore,vydiswaran2011content}. Many truth discovery approaches are tailored to categorical data and thus assume there is a single objective truth that can be derived from the claims of different sources \cite{li2016survey}. Faitcrowd~\cite{ma2015faitcrowd} assumes an objective truth in the answer set and uses a probabilistic generative model to perform fine-grained truth discovery. It jointly models the generation of questions and answers to estimate the source reliability and correct answer. On the other hand,~\citet{wan2016truth} propose trustworthy \emph{opinion} discovery where the true value of an entity is modeled as a random variable with a probability density function instead of a single value.

Some truth discovery approaches also leverage text data to identify correct responses better.~\citet{li2017reliable} proposed a model for capturing semantic meanings of crowd provided diagnosis in a Chinese medical forum. In particular, they use a medical-related dictionary to extract terms in the response text and learn their semantic representations to discover trustworthy answers from non-expert users in crowdsourced diagnosis.
\citet{zhang2018texttruth} proposed a Bayesian approach to capture the multifactorial property of text answers and used semantic representations of keywords to mitigate the diversity of words in answers. To model the user reliability, the authors proposed a two-fold reliability metric that uses both false positive and true positive rates. These approaches only use certain keywords for each answer and are thus, limited in their scope.
