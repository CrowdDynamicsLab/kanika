\chapter{Modeling relational aspects of user-generated content}
\label{chap:induced}
In this chapter, we propose to incorporate user behavioral information as metadata to improve the attribute estimation of user-generated content.
For this purpose, we focus on the task of quality estimation of user-provided answers for best answer selection task in CQA forums. Current approaches predict answer quality in isolation of the other answers to the question and user activity across the forum (other posted questions or answers). This assumption is limiting as the best answer is, in general, selected based on how it differs from other answers to the same question. Similarly, answers given by expert users tend to be of higher quality. We leverage these cues by inducing multiple graphs between these answers based on similarity and contrast in the behavior of users providing the answers. Finally, multiple graphs expressing semantically diverse relationships
are merged to predict the best answer to a question \cite{induced}.

\section{Overview}
Individuals often visit Community Question Answer (CQA) forums, like StackExchange, to seek answers to nuanced questions that are not readily available on web-search engines.
Unlike other familiar Learning-to-Rank problems in the IR community~\cite{LambdaMart, LambdaNet}, CQA platforms can identify and leverage past questions asked by similar users and relevant answers to those questions.
However, for CQA sites like StackExchange, individuals who post questions may label an answer as `accepted,' but other questions with answers (about $47$\% in our analysis) have none labeled as `accepted.' On other CQA sites like Reddit, there is no mechanism for a person to label an answer as `accepted.' As a first step to address the individual's information needs, in this work, we focus on the problem of identifying accepted answers on StackExchange.

One approach to identify relevant answers is to identify salient features for each question-answer tuple $(q,a)$ and treat it as a supervised classification problem~\citep{BurelMA16,  JendersKN16, TianZL13, TianL16}. Deep Text Models further develop this approach~\cite{ZhangLSW17, WuWS18, WangN15, SukhbaatarSWF15}. These models learn the optimal text representation of $(q,a)$ tuple to select the most relevant answer. While the deep text models are sophisticated, text-based models are computationally expensive to train. Furthermore, there are limitations to examining $(q,a)$ tuples in isolation: an answer is "relevant" \emph{in relationship} to other answers to the same question; second, it ignores the fact that same user may answer multiple questions in the forum.
These relational aspects of user-generated content provide a unique dimension that is absent in textual search. However, there is only limited work in the context of identification of "best answers" among user-generated content that exploit these implicit and explicit connections.
Thus, our key proposal is to use this alternative approach and build a flexible and expressive framework to incorporate the relational aspects of user-generated content for the answer selection task.

Relational aspects are best captured as graphs connecting content.
Graph Convolutional Networks (GCNs) is a popular technique to incorporate graph structure, and are used in tasks including node classification \cite{gcn} and link prediction~\cite{relationalGCN}. Extensions to the basic GCN model include signed networks~\cite{signedgcn}, inductive settings~\cite{graphsage} and multiple relations~\cite{DualGCN, relationalGCN}.
While GCNs are a plausible approach, we need to overcome a fundamental implicit assumption in prior work before we can apply it to our problem. Prior work in GCNs adopt label sharing amongst nodes; label sharing implicitly assumes similarity between two nodes connected by an edge. In the Answer Selection problem, however, answers to the same question connected by an edge may not share the acceptance label. In particular, we may label an answer as `accepted' based on how it differs from other answers to the same question.
In other words, the relational views (or graphs) could capture similarity or contrast between connected content, depending on the relation in consideration.
However, Signed GCNs~\cite{signedgcn} can not capture this contrast despite their ability to incorporate signed edges. Graph attention networks~\cite{graphattention} also could not learn negative attention weight over neighbors as weights are the output of a softmax operation.

Thus, we develop a novel framework to model the diverse relations between content through a separate \textit{induced} graph across $(q,a)$ tuples. The key idea is to use diverse strategies---label depends only on the answer (reflexive), the label is determined in contrast with the other answers to the question (contrastive), and label sharing among answers across questions if it contrasts with other answers similarly(similar contrast)---to identify the accepted answer.
Each strategy \textit{induces} a graph between $(q,a)$ tuples and then uses a particular label selection mechanism to identify the accepted answer. Our strategies generalize to a broader principle: pick an equivalence relation to induce a graph comprising cliques, and then pick a label selection mechanism (label sharing or label contrast) within each clique. We show how to develop GCN architecture to operationalize the specific label selection mechanism (label sharing or label contrast). Then, we aggregate results across strategies through a boosting framework to identify the label for each $(q,a)$ tuple. Our Contributions are as follows:
\begin{description}
  \item[Modular, Induced Relational Framework:] We introduce a modular framework that separates the construction of the graph with the label selection mechanism. In contrast,  prior work in answer selection (e.g.,~\citep{BurelMA16,  JendersKN16, TianZL13, TianL16}.) looked at individual tuples, and work on GCNs (e.g.,~\citep{gcn, DualGCN}) use the given graph (i.e., no induced graphs) and with similarity as a mechanism for label propagation. We use equivalence relations to induce a graph comprising cliques and identify two label assignment mechanisms---label contrast, label sharing. Then, we show how to encode these assignment mechanisms in GCNs. In particular, we show that the use of equivalence relations allows us to perform \textit{exact} convolution in GCNs. We call our framework Induced Relational GCN (IR-GCN). Our framework allows for parallelization and applies to other problems that need application semantics to induce graphs independent of any existing graphs\cite{InducedGraph}.
  \item[Discriminative Semantics:] We show how to encode the notion of label contrast between a vertex and a group of vertices in GCNs. Label contrast is critical to the problem of best answer selection. Related work in GCNs (e.g.,~\citep{gcn, DualGCN}) emphasizes node similarity, including the work on signed graphs~\cite{signedgcn}. In~\citep{signedgcn}, contrast is a property of an edge, not a group, and is not expressive enough for our problem. We show that our encoding of contrast creates \textit{discriminative magnification}---the separation between nodes in the embedding space is most meaningful at smaller clique sizes; the effect decreases with clique size.

  \item[Boosted Architecture:]  We show through extensive empirical results that using common boosting techniques improves learning in our convolutional model. This improvement is a surprising result since much of the work on neural architectures develops stacking, fusion, or aggregator architectures.

\end{description}

We conducted extensive experiments using our IR-GCN framework with excellent experimental results on the popular CQA forum---StackExchange. For our analysis, we collect data from 50 communities---the ten largest communities from each of the five StackExchange\footnote{https://stackexchange.com/sites} categories. We achieved an improvement of over 4\% accuracy and 2.5\% in MRR, on average, over state-of-the-art baselines. We also provide Reddit \footnote{https://www.reddit.com/} results using expert answers as a proxy for acceptance, to overcome the absence of explicit labels. Finally, we show that our model is more robust to label sparsity compared to alternate GCN based multi-relational approaches.

We organize the rest of this chapter as follows. In \cref{sec:problem}, we formulate our problem statement and then discuss induced relations for the Answer Selection problem in \cref{sec:Induced Relational Views}. We then detail the operationalization of these induced relations in the Graph Convolution framework in \cref{sec:gcn} and introduce our gradient boosting based aggregator approach in \cref{sec:aggregation}. \Cref{sec:induced_experiments} describes experiments and \Cref{sec:discussion} describes further ablation studies. We finally conclude in \cref{sec:conclude}.
